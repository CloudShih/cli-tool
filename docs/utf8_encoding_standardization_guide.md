# UTF-8 ç·¨ç¢¼æ¨™æº–åŒ–è™•ç†æŒ‡å—

**æ—¥æœŸ**: 2025-08-18  
**é¡åˆ¥**: ç·¨ç¢¼è™•ç†ç³»çµ±  
**ç›®çš„**: å¯¦ç¾å…¨é¢çš„ UTF-8 ç·¨ç¢¼æ¨™æº–åŒ–è™•ç†ï¼Œè§£æ±ºè·¨å¹³å°ç·¨ç¢¼å•é¡Œ  

## æ¦‚è¿°

æœ¬æŒ‡å—è©³è¿°äº†å¦‚ä½•åœ¨ PyQt5 æ‡‰ç”¨ç¨‹å¼ä¸­å¯¦ç¾å®Œæ•´çš„ UTF-8 ç·¨ç¢¼æ¨™æº–åŒ–è™•ç†ç³»çµ±ï¼ŒåŒ…æ‹¬æ–‡ä»¶è™•ç†ã€å‘½ä»¤åˆ—å·¥å…·æ•´åˆã€ä¸­æ–‡æ”¯æ´ã€ç·¨ç¢¼æª¢æ¸¬å’Œè½‰æ›åŠŸèƒ½ã€‚åŸºæ–¼ç¾æœ‰çš„ CLI Tool å°ˆæ¡ˆæ¶æ§‹å’Œå¯¦éš›é‡åˆ°çš„ç·¨ç¢¼å•é¡Œï¼Œæä¾›å®Œæ•´çš„ç·¨ç¢¼è§£æ±ºæ–¹æ¡ˆã€‚

---

## ç·¨ç¢¼å•é¡Œåˆ†æ

### ç•¶å‰ç™¼ç¾çš„å•é¡Œ

åŸºæ–¼ lesson learn æ–‡ä»¶åˆ†æï¼Œä¸»è¦ç·¨ç¢¼å•é¡ŒåŒ…æ‹¬ï¼š

1. **Windows cp950 ç·¨ç¢¼é™åˆ¶**
   - Windows ä¸­æ–‡ç’°å¢ƒé è¨­ä½¿ç”¨ cp950 ç·¨ç¢¼
   - ç„¡æ³•è™•ç†å®Œæ•´çš„ Unicode å­—ç¬¦é›†
   - åœ¨ console è¼¸å‡º Emoji å’Œç‰¹æ®Š Unicode å­—ç¬¦æ™‚å´©æ½°

2. **æ··åˆç·¨ç¢¼ç’°å¢ƒ**
   - Python æºä»£ç¢¼ï¼šUTF-8
   - ç³»çµ±æ§åˆ¶å°ï¼šcp950 (Windows) / UTF-8 (Linux/Mac)
   - å¤–éƒ¨å·¥å…·è¼¸å‡ºï¼šå¤šç¨®ç·¨ç¢¼æ ¼å¼

3. **CLI å·¥å…·è¼¸å‡ºç·¨ç¢¼ä¸ä¸€è‡´**
   - ripgrepã€fdã€pandoc ç­‰å·¥å…·çš„è¼¸å‡ºç·¨ç¢¼å·®ç•°
   - éƒ¨åˆ†å·¥å…·é è¨­è¼¸å‡ºç‚ºç³»çµ±ç·¨ç¢¼
   - éœ€è¦çµ±ä¸€è½‰æ›ç‚º UTF-8 è™•ç†

### ç³»çµ±æ¶æ§‹åœ–

```
UTF-8 Encoding System
â”œâ”€â”€ Encoding Detection (ç·¨ç¢¼æª¢æ¸¬)
â”‚   â”œâ”€â”€ File Encoding Detector (æª”æ¡ˆç·¨ç¢¼æª¢æ¸¬å™¨)
â”‚   â”œâ”€â”€ Text Encoding Analyzer (æ–‡æœ¬ç·¨ç¢¼åˆ†æå™¨)
â”‚   â””â”€â”€ System Encoding Profiler (ç³»çµ±ç·¨ç¢¼åˆ†æå™¨)
â”œâ”€â”€ Encoding Conversion (ç·¨ç¢¼è½‰æ›)
â”‚   â”œâ”€â”€ Universal Text Converter (é€šç”¨æ–‡æœ¬è½‰æ›å™¨)
â”‚   â”œâ”€â”€ File Encoding Converter (æª”æ¡ˆç·¨ç¢¼è½‰æ›å™¨)
â”‚   â””â”€â”€ Stream Encoding Processor (æµå¼ç·¨ç¢¼è™•ç†å™¨)
â”œâ”€â”€ CLI Tools Integration (CLI å·¥å…·æ•´åˆ)
â”‚   â”œâ”€â”€ Command Output Processor (å‘½ä»¤è¼¸å‡ºè™•ç†å™¨)
â”‚   â”œâ”€â”€ Subprocess Encoding Handler (å­ç¨‹åºç·¨ç¢¼è™•ç†å™¨)
â”‚   â””â”€â”€ Cross-platform Compatibility (è·¨å¹³å°å…¼å®¹æ€§)
â”œâ”€â”€ Chinese & CJK Support (ä¸­æ–‡èˆ‡ CJK æ”¯æ´)
â”‚   â”œâ”€â”€ CJK Character Handler (CJK å­—ç¬¦è™•ç†å™¨)
â”‚   â”œâ”€â”€ Traditional/Simplified Converter (ç¹ç°¡è½‰æ›å™¨)
â”‚   â””â”€â”€ Font Rendering Support (å­—é«”æ¸²æŸ“æ”¯æ´)
â””â”€â”€ Error Handling & Recovery (éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©)
    â”œâ”€â”€ Encoding Error Handler (ç·¨ç¢¼éŒ¯èª¤è™•ç†å™¨)
    â”œâ”€â”€ Fallback Mechanisms (å¾Œå‚™æ©Ÿåˆ¶)
    â””â”€â”€ Data Recovery Tools (è³‡æ–™æ¢å¾©å·¥å…·)
```

---

## 1. ç·¨ç¢¼æª¢æ¸¬ç³»çµ±

### é€šç”¨ç·¨ç¢¼æª¢æ¸¬å™¨

```python
"""
UTF-8 ç·¨ç¢¼æª¢æ¸¬å’Œè™•ç†ç³»çµ±
æä¾›å…¨é¢çš„ç·¨ç¢¼æª¢æ¸¬ã€è½‰æ›å’Œæ¨™æº–åŒ–åŠŸèƒ½
"""

import os
import sys
import chardet
import codecs
import logging
from typing import Optional, Tuple, List, Dict, Union, Any
from pathlib import Path
from dataclasses import dataclass
from enum import Enum
from PyQt5.QtCore import QObject, pyqtSignal

logger = logging.getLogger(__name__)

class EncodingType(Enum):
    """ç·¨ç¢¼é¡å‹æšèˆ‰"""
    UTF8 = "utf-8"
    UTF8_BOM = "utf-8-sig"
    UTF16 = "utf-16"
    UTF16_BE = "utf-16-be"
    UTF16_LE = "utf-16-le"
    UTF32 = "utf-32"
    ASCII = "ascii"
    LATIN1 = "latin1"
    CP1252 = "cp1252"
    CP950 = "cp950"  # Traditional Chinese (Taiwan)
    GBK = "gbk"      # Simplified Chinese
    GB2312 = "gb2312" # Simplified Chinese (older)
    BIG5 = "big5"    # Traditional Chinese
    SHIFT_JIS = "shift_jis"  # Japanese
    EUC_JP = "euc-jp"        # Japanese
    EUC_KR = "euc-kr"        # Korean
    ISO_8859_1 = "iso-8859-1"
    UNKNOWN = "unknown"

@dataclass
class EncodingDetectionResult:
    """ç·¨ç¢¼æª¢æ¸¬çµæœ"""
    encoding: str
    confidence: float
    encoding_type: EncodingType
    byte_order_mark: bool = False
    language: Optional[str] = None
    error_count: int = 0
    
    @property
    def is_reliable(self) -> bool:
        """åˆ¤æ–·æª¢æ¸¬çµæœæ˜¯å¦å¯é """
        return self.confidence >= 0.8 and self.error_count == 0
    
    @property
    def is_utf8_compatible(self) -> bool:
        """åˆ¤æ–·æ˜¯å¦èˆ‡ UTF-8 å…¼å®¹"""
        return self.encoding_type in [
            EncodingType.UTF8, 
            EncodingType.UTF8_BOM, 
            EncodingType.ASCII
        ]

class UniversalEncodingDetector:
    """é€šç”¨ç·¨ç¢¼æª¢æ¸¬å™¨"""
    
    # å¸¸è¦‹ç·¨ç¢¼çš„ BOM æ¨™è¨˜
    BOM_SIGNATURES = {
        b'\xff\xfe': 'utf-16-le',
        b'\xfe\xff': 'utf-16-be',
        b'\xff\xfe\x00\x00': 'utf-32-le',
        b'\x00\x00\xfe\xff': 'utf-32-be',
        b'\xef\xbb\xbf': 'utf-8-sig',
    }
    
    # ä¸­æ–‡ç·¨ç¢¼ç‰¹å¾å­—ç¯€ç¯„åœ
    CJK_ENCODING_RANGES = {
        'gbk': [(0x81, 0xfe), (0x40, 0xfe)],
        'big5': [(0xa1, 0xfe), (0x40, 0xfe)],
        'cp950': [(0x81, 0xfe), (0x40, 0xfe)],
        'gb2312': [(0xa1, 0xfe), (0xa1, 0xfe)],
    }
    
    def __init__(self):
        self.detection_history: List[EncodingDetectionResult] = []
        self.cache: Dict[str, EncodingDetectionResult] = {}
        
    def detect_file_encoding(self, file_path: Union[str, Path]) -> EncodingDetectionResult:
        """æª¢æ¸¬æª”æ¡ˆç·¨ç¢¼"""
        file_path = Path(file_path)
        cache_key = f"file:{file_path}:{file_path.stat().st_mtime}"
        
        # æª¢æŸ¥å¿«å–
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        try:
            # è®€å–æª”æ¡ˆé–‹é ­ç”¨æ–¼æª¢æ¸¬
            with open(file_path, 'rb') as f:
                raw_data = f.read(min(10240, file_path.stat().st_size))  # æœ€å¤šè®€å– 10KB
            
            result = self.detect_bytes_encoding(raw_data, str(file_path))
            
            # å¿«å–çµæœ
            self.cache[cache_key] = result
            return result
            
        except Exception as e:
            logger.error(f"Error detecting file encoding {file_path}: {e}")
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=0.0,
                encoding_type=EncodingType.UTF8,
                error_count=1
            )
    
    def detect_bytes_encoding(self, data: bytes, context: str = "") -> EncodingDetectionResult:
        """æª¢æ¸¬å­—ç¯€æ•¸æ“šç·¨ç¢¼"""
        if not data:
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=1.0,
                encoding_type=EncodingType.UTF8
            )
        
        # 1. æª¢æ¸¬ BOM
        bom_result = self._detect_bom(data)
        if bom_result:
            return bom_result
        
        # 2. å˜—è©¦ UTF-8 è§£ç¢¼
        utf8_result = self._try_utf8_decode(data)
        if utf8_result.is_reliable:
            return utf8_result
        
        # 3. ä½¿ç”¨ chardet æª¢æ¸¬
        chardet_result = self._chardet_detection(data)
        
        # 4. ä¸­æ–‡ç·¨ç¢¼ç‰¹æ®Šæª¢æ¸¬
        cjk_result = self._detect_cjk_encoding(data)
        
        # 5. é¸æ“‡æœ€ä½³çµæœ
        candidates = [utf8_result, chardet_result, cjk_result]
        candidates = [r for r in candidates if r is not None]
        
        if not candidates:
            return EncodingDetectionResult(
                encoding="latin1",
                confidence=0.5,
                encoding_type=EncodingType.LATIN1
            )
        
        # æŒ‰å¯é æ€§æ’åº
        best_result = max(candidates, key=lambda x: (x.is_reliable, x.confidence))
        
        logger.debug(f"Detected encoding for {context}: {best_result.encoding} "
                    f"(confidence: {best_result.confidence:.2f})")
        
        return best_result
    
    def _detect_bom(self, data: bytes) -> Optional[EncodingDetectionResult]:
        """æª¢æ¸¬å­—ç¯€é †åºæ¨™è¨˜ (BOM)"""
        for bom, encoding in self.BOM_SIGNATURES.items():
            if data.startswith(bom):
                encoding_type = EncodingType(encoding) if encoding in [e.value for e in EncodingType] else EncodingType.UNKNOWN
                return EncodingDetectionResult(
                    encoding=encoding,
                    confidence=1.0,
                    encoding_type=encoding_type,
                    byte_order_mark=True
                )
        return None
    
    def _try_utf8_decode(self, data: bytes) -> EncodingDetectionResult:
        """å˜—è©¦ UTF-8 è§£ç¢¼"""
        try:
            text = data.decode('utf-8')
            # æª¢æŸ¥æ˜¯å¦åŒ…å«æ›¿æ›å­—ç¬¦
            replacement_count = text.count('\ufffd')
            confidence = 1.0 - (replacement_count / max(1, len(text)))
            
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=confidence,
                encoding_type=EncodingType.UTF8,
                error_count=replacement_count
            )
        except UnicodeDecodeError as e:
            # è¨ˆç®—éŒ¯èª¤ç‡
            error_rate = len(e.args) / len(data) if len(data) > 0 else 1.0
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=1.0 - error_rate,
                encoding_type=EncodingType.UTF8,
                error_count=1
            )
    
    def _chardet_detection(self, data: bytes) -> Optional[EncodingDetectionResult]:
        """ä½¿ç”¨ chardet é€²è¡Œæª¢æ¸¬"""
        try:
            result = chardet.detect(data)
            if result and result['encoding']:
                encoding = result['encoding'].lower()
                confidence = result['confidence']
                
                # æ¨™æº–åŒ–ç·¨ç¢¼åç¨±
                encoding = self._normalize_encoding_name(encoding)
                
                # ç¢ºå®šç·¨ç¢¼é¡å‹
                try:
                    encoding_type = EncodingType(encoding)
                except ValueError:
                    encoding_type = EncodingType.UNKNOWN
                
                # æª¢æ¸¬èªè¨€
                language = self._detect_language_from_encoding(encoding)
                
                return EncodingDetectionResult(
                    encoding=encoding,
                    confidence=confidence,
                    encoding_type=encoding_type,
                    language=language
                )
        except Exception as e:
            logger.warning(f"chardet detection failed: {e}")
        
        return None
    
    def _detect_cjk_encoding(self, data: bytes) -> Optional[EncodingDetectionResult]:
        """æª¢æ¸¬ä¸­æ—¥éŸ“ (CJK) ç·¨ç¢¼"""
        # å˜—è©¦å¸¸è¦‹çš„ CJK ç·¨ç¢¼
        cjk_encodings = ['gbk', 'big5', 'cp950', 'gb2312', 'shift_jis', 'euc-jp', 'euc-kr']
        
        best_result = None
        best_score = 0
        
        for encoding in cjk_encodings:
            try:
                decoded = data.decode(encoding)
                # è¨ˆç®— CJK å­—ç¬¦æ¯”ä¾‹
                cjk_chars = sum(1 for char in decoded if self._is_cjk_character(char))
                cjk_ratio = cjk_chars / len(decoded) if decoded else 0
                
                # å¦‚æœåŒ…å«è¶³å¤ çš„ CJK å­—ç¬¦ï¼Œèªç‚ºæª¢æ¸¬æˆåŠŸ
                if cjk_ratio > 0.1:  # è¶…é 10% CJK å­—ç¬¦
                    score = cjk_ratio * 0.9  # åŸºç¤åˆ†æ•¸
                    
                    if score > best_score:
                        best_score = score
                        encoding_type = EncodingType(encoding) if encoding in [e.value for e in EncodingType] else EncodingType.UNKNOWN
                        best_result = EncodingDetectionResult(
                            encoding=encoding,
                            confidence=score,
                            encoding_type=encoding_type,
                            language=self._detect_language_from_encoding(encoding)
                        )
                        
            except (UnicodeDecodeError, LookupError):
                continue
        
        return best_result
    
    def _is_cjk_character(self, char: str) -> bool:
        """æª¢æŸ¥æ˜¯å¦ç‚º CJK å­—ç¬¦"""
        code_point = ord(char)
        # Unicode CJK ç¯„åœ
        cjk_ranges = [
            (0x4E00, 0x9FFF),    # CJK Unified Ideographs
            (0x3400, 0x4DBF),    # CJK Extension A
            (0x20000, 0x2A6DF),  # CJK Extension B
            (0x2A700, 0x2B73F),  # CJK Extension C
            (0x2B740, 0x2B81F),  # CJK Extension D
            (0x2B820, 0x2CEAF),  # CJK Extension E
            (0x3300, 0x33FF),    # CJK Compatibility
            (0xFE30, 0xFE4F),    # CJK Compatibility Forms
            (0xF900, 0xFAFF),    # CJK Compatibility Ideographs
        ]
        
        return any(start <= code_point <= end for start, end in cjk_ranges)
    
    def _normalize_encoding_name(self, encoding: str) -> str:
        """æ¨™æº–åŒ–ç·¨ç¢¼åç¨±"""
        encoding = encoding.lower().replace('-', '').replace('_', '')
        
        # ç·¨ç¢¼åç¨±å°æ‡‰è¡¨
        encoding_map = {
            'utf8': 'utf-8',
            'utf16': 'utf-16',
            'utf32': 'utf-32',
            'gb18030': 'gbk',
            'chinese': 'gbk',
            'big5hkscs': 'big5',
            'eucjp': 'euc-jp',
            'euckr': 'euc-kr',
            'shiftjis': 'shift_jis',
            'sjis': 'shift_jis',
            'iso88591': 'iso-8859-1',
            'latin1': 'iso-8859-1',
            'cp1252': 'cp1252',
            'windows1252': 'cp1252',
        }
        
        return encoding_map.get(encoding, encoding)
    
    def _detect_language_from_encoding(self, encoding: str) -> Optional[str]:
        """å¾ç·¨ç¢¼æ¨æ¸¬èªè¨€"""
        language_map = {
            'gbk': 'zh-CN',
            'gb2312': 'zh-CN', 
            'big5': 'zh-TW',
            'cp950': 'zh-TW',
            'shift_jis': 'ja',
            'euc-jp': 'ja',
            'euc-kr': 'ko',
        }
        return language_map.get(encoding)
    
    def detect_text_encoding(self, text: str) -> EncodingDetectionResult:
        """æª¢æ¸¬æ–‡æœ¬å­—ç¬¦ä¸²çš„åŸå§‹ç·¨ç¢¼ï¼ˆé€šéå­—ç¬¦åˆ†æï¼‰"""
        if not text:
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=1.0,
                encoding_type=EncodingType.UTF8
            )
        
        # åˆ†æå­—ç¬¦çµ„æˆ
        ascii_count = sum(1 for char in text if ord(char) < 128)
        cjk_count = sum(1 for char in text if self._is_cjk_character(char))
        total_chars = len(text)
        
        ascii_ratio = ascii_count / total_chars
        cjk_ratio = cjk_count / total_chars
        
        # åŸºæ–¼å­—ç¬¦åˆ†æåˆ¤æ–·ç·¨ç¢¼
        if ascii_ratio == 1.0:
            return EncodingDetectionResult(
                encoding="ascii",
                confidence=1.0,
                encoding_type=EncodingType.ASCII
            )
        elif cjk_ratio > 0.1:
            # åŒ…å«å¤§é‡ CJK å­—ç¬¦ï¼Œå¯èƒ½æ˜¯ä¸­æ–‡ç·¨ç¢¼è½‰æ›è€Œä¾†
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=0.8,
                encoding_type=EncodingType.UTF8,
                language="zh"
            )
        else:
            return EncodingDetectionResult(
                encoding="utf-8",
                confidence=0.9,
                encoding_type=EncodingType.UTF8
            )

# å…¨åŸŸç·¨ç¢¼æª¢æ¸¬å™¨å¯¦ä¾‹
encoding_detector = UniversalEncodingDetector()
```

---

## 2. ç·¨ç¢¼è½‰æ›ç³»çµ±

### é€šç”¨ç·¨ç¢¼è½‰æ›å™¨

```python
"""
é€šç”¨ç·¨ç¢¼è½‰æ›ç³»çµ±
æä¾›å®‰å…¨å¯é çš„ç·¨ç¢¼è½‰æ›åŠŸèƒ½
"""

class EncodingConverter:
    """ç·¨ç¢¼è½‰æ›å™¨"""
    
    def __init__(self):
        self.conversion_history: List[Dict[str, Any]] = []
        self.error_handlers = {
            'strict': 'strict',
            'ignore': 'ignore', 
            'replace': 'replace',
            'xmlcharrefreplace': 'xmlcharrefreplace',
            'backslashreplace': 'backslashreplace',
            'smart_replace': self._smart_error_handler
        }
        
    def convert_text(self, 
                    text: str, 
                    target_encoding: str = 'utf-8',
                    source_encoding: Optional[str] = None,
                    error_handling: str = 'smart_replace') -> Tuple[str, bool]:
        """
        è½‰æ›æ–‡æœ¬ç·¨ç¢¼
        
        Args:
            text: æºæ–‡æœ¬
            target_encoding: ç›®æ¨™ç·¨ç¢¼
            source_encoding: æºç·¨ç¢¼ï¼ˆå¦‚æœå·²çŸ¥ï¼‰
            error_handling: éŒ¯èª¤è™•ç†æ–¹å¼
            
        Returns:
            (è½‰æ›å¾Œçš„æ–‡æœ¬, æ˜¯å¦æˆåŠŸ)
        """
        try:
            # å¦‚æœå·²ç¶“æ˜¯å­—ç¬¦ä¸²ä¸”ç›®æ¨™æ˜¯ UTF-8ï¼Œé€šå¸¸ä¸éœ€è¦è½‰æ›
            if target_encoding.lower() in ['utf-8', 'utf8'] and isinstance(text, str):
                # é©—è­‰æ˜¯å¦ç‚ºæœ‰æ•ˆ UTF-8
                try:
                    text.encode('utf-8')
                    return text, True
                except UnicodeEncodeError:
                    pass
            
            # å¦‚æœæœªæŒ‡å®šæºç·¨ç¢¼ï¼Œå˜—è©¦æª¢æ¸¬
            if source_encoding is None:
                detection_result = encoding_detector.detect_text_encoding(text)
                source_encoding = detection_result.encoding
                logger.debug(f"Detected source encoding: {source_encoding}")
            
            # åŸ·è¡Œè½‰æ›
            if isinstance(text, str):
                # å­—ç¬¦ä¸² -> å­—ç¯€ -> å­—ç¬¦ä¸²
                try:
                    bytes_data = text.encode(source_encoding, errors='strict')
                    converted_text = bytes_data.decode(target_encoding, errors='strict')
                    return converted_text, True
                except (UnicodeEncodeError, UnicodeDecodeError):
                    # ä½¿ç”¨éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
                    return self._convert_with_error_handling(
                        text, source_encoding, target_encoding, error_handling
                    )
            else:
                # å‡è¨­æ˜¯å­—ç¯€æ•¸æ“š
                converted_text = text.decode(target_encoding, errors=error_handling)
                return converted_text, True
                
        except Exception as e:
            logger.error(f"Encoding conversion failed: {e}")
            return text, False
    
    def convert_file(self, 
                    file_path: Union[str, Path],
                    target_encoding: str = 'utf-8',
                    source_encoding: Optional[str] = None,
                    backup: bool = True,
                    error_handling: str = 'smart_replace') -> bool:
        """
        è½‰æ›æª”æ¡ˆç·¨ç¢¼
        
        Args:
            file_path: æª”æ¡ˆè·¯å¾‘
            target_encoding: ç›®æ¨™ç·¨ç¢¼
            source_encoding: æºç·¨ç¢¼
            backup: æ˜¯å¦å‰µå»ºå‚™ä»½
            error_handling: éŒ¯èª¤è™•ç†æ–¹å¼
            
        Returns:
            æ˜¯å¦è½‰æ›æˆåŠŸ
        """
        file_path = Path(file_path)
        
        try:
            # æª¢æ¸¬æºç·¨ç¢¼
            if source_encoding is None:
                detection_result = encoding_detector.detect_file_encoding(file_path)
                source_encoding = detection_result.encoding
                
                if not detection_result.is_reliable:
                    logger.warning(f"Encoding detection not reliable for {file_path}, "
                                 f"confidence: {detection_result.confidence}")
            
            # å¦‚æœå·²ç¶“æ˜¯ç›®æ¨™ç·¨ç¢¼ï¼Œè·³é
            if source_encoding.lower() == target_encoding.lower():
                logger.info(f"File {file_path} already in target encoding {target_encoding}")
                return True
            
            # è®€å–åŸå§‹å…§å®¹
            with open(file_path, 'r', encoding=source_encoding, errors=error_handling) as f:
                content = f.read()
            
            # å‰µå»ºå‚™ä»½
            if backup:
                backup_path = file_path.with_suffix(file_path.suffix + '.bak')
                file_path.rename(backup_path)
                logger.info(f"Created backup: {backup_path}")
            
            # å¯«å…¥è½‰æ›å¾Œçš„å…§å®¹
            with open(file_path, 'w', encoding=target_encoding, errors=error_handling) as f:
                f.write(content)
            
            logger.info(f"Successfully converted {file_path} from {source_encoding} to {target_encoding}")
            
            # è¨˜éŒ„è½‰æ›æ­·å²
            self.conversion_history.append({
                'timestamp': import datetime.datetime.now().isoformat(),
                'file_path': str(file_path),
                'source_encoding': source_encoding,
                'target_encoding': target_encoding,
                'success': True
            })
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to convert file {file_path}: {e}")
            
            # è¨˜éŒ„å¤±æ•—æ­·å²
            self.conversion_history.append({
                'timestamp': datetime.datetime.now().isoformat(),
                'file_path': str(file_path),
                'source_encoding': source_encoding,
                'target_encoding': target_encoding,
                'success': False,
                'error': str(e)
            })
            
            return False
    
    def batch_convert_directory(self,
                               directory_path: Union[str, Path],
                               target_encoding: str = 'utf-8',
                               file_patterns: List[str] = None,
                               recursive: bool = True) -> Dict[str, Any]:
        """
        æ‰¹é‡è½‰æ›ç›®éŒ„ä¸­çš„æª”æ¡ˆ
        
        Args:
            directory_path: ç›®éŒ„è·¯å¾‘
            target_encoding: ç›®æ¨™ç·¨ç¢¼
            file_patterns: æª”æ¡ˆåŒ¹é…æ¨¡å¼ï¼ˆå¦‚ ['*.py', '*.txt']ï¼‰
            recursive: æ˜¯å¦éè¿´è™•ç†å­ç›®éŒ„
            
        Returns:
            è½‰æ›çµæœçµ±è¨ˆ
        """
        directory_path = Path(directory_path)
        
        if not directory_path.exists():
            raise FileNotFoundError(f"Directory not found: {directory_path}")
        
        if file_patterns is None:
            file_patterns = ['*.txt', '*.py', '*.js', '*.html', '*.css', '*.md', '*.json', '*.xml']
        
        # æ”¶é›†è¦è½‰æ›çš„æª”æ¡ˆ
        files_to_convert = []
        for pattern in file_patterns:
            if recursive:
                files_to_convert.extend(directory_path.rglob(pattern))
            else:
                files_to_convert.extend(directory_path.glob(pattern))
        
        # å»é‡ä¸¦æ’åº
        files_to_convert = sorted(set(files_to_convert))
        
        logger.info(f"Found {len(files_to_convert)} files to convert in {directory_path}")
        
        # åŸ·è¡Œè½‰æ›
        results = {
            'total_files': len(files_to_convert),
            'success_count': 0,
            'failure_count': 0,
            'skipped_count': 0,
            'failed_files': [],
            'converted_files': []
        }
        
        for file_path in files_to_convert:
            try:
                success = self.convert_file(file_path, target_encoding)
                if success:
                    results['success_count'] += 1
                    results['converted_files'].append(str(file_path))
                else:
                    results['failure_count'] += 1
                    results['failed_files'].append(str(file_path))
                    
            except Exception as e:
                logger.error(f"Error converting {file_path}: {e}")
                results['failure_count'] += 1
                results['failed_files'].append(str(file_path))
        
        return results
    
    def _convert_with_error_handling(self, 
                                   text: str, 
                                   source_encoding: str,
                                   target_encoding: str,
                                   error_handling: str) -> Tuple[str, bool]:
        """ä½¿ç”¨éŒ¯èª¤è™•ç†æ©Ÿåˆ¶é€²è¡Œè½‰æ›"""
        if error_handling == 'smart_replace':
            return self._smart_error_handler(text, source_encoding, target_encoding)
        
        try:
            # ä½¿ç”¨æ¨™æº–éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
            if isinstance(text, str):
                bytes_data = text.encode(source_encoding, errors=error_handling)
                converted_text = bytes_data.decode(target_encoding, errors=error_handling)
            else:
                converted_text = text.decode(target_encoding, errors=error_handling)
            
            return converted_text, True
            
        except Exception as e:
            logger.error(f"Error handling conversion failed: {e}")
            return text, False
    
    def _smart_error_handler(self, text: str, source_encoding: str, target_encoding: str) -> Tuple[str, bool]:
        """æ™ºèƒ½éŒ¯èª¤è™•ç†"""
        try:
            # å˜—è©¦é€å­—ç¬¦è½‰æ›ï¼Œå°æœ‰å•é¡Œçš„å­—ç¬¦é€²è¡Œç‰¹æ®Šè™•ç†
            result = []
            errors = 0
            
            for char in text:
                try:
                    # å˜—è©¦ç›´æ¥è½‰æ›
                    char.encode(target_encoding)
                    result.append(char)
                except UnicodeEncodeError:
                    # å˜—è©¦æ›¿æ›ç‚ºé¡ä¼¼å­—ç¬¦
                    replacement = self._find_replacement_char(char, target_encoding)
                    if replacement:
                        result.append(replacement)
                        errors += 1
                    else:
                        result.append('?')
                        errors += 1
            
            converted_text = ''.join(result)
            success = errors == 0
            
            if errors > 0:
                logger.warning(f"Smart error handling replaced {errors} characters")
            
            return converted_text, success
            
        except Exception as e:
            logger.error(f"Smart error handling failed: {e}")
            return text, False
    
    def _find_replacement_char(self, char: str, target_encoding: str) -> Optional[str]:
        """æ‰¾åˆ°å­—ç¬¦çš„æ›¿æ›å­—ç¬¦"""
        # å¸¸è¦‹å­—ç¬¦æ›¿æ›è¡¨
        replacement_map = {
            # ä¸­æ–‡æ¨™é»ç¬¦è™Ÿæ›¿æ›
            'ï¼š': ':',
            'ï¼›': ';',
            'ï¼Œ': ',',
            'ã€‚': '.',
            'ï¼Ÿ': '?',
            'ï¼': '!',
            '"': '"',
            '"': '"',
            ''': "'",
            ''': "'",
            'ï¼ˆ': '(',
            'ï¼‰': ')',
            'ã€': '[',
            'ã€‘': ']',
            # Emoji æ›¿æ›
            'ğŸ˜€': ':)',
            'ğŸ˜‚': ':D',
            'ğŸ˜­': ':(',
            'â¤': '<3',
            'ğŸ‘': '+1',
            'ğŸ‘': '-1',
            # ç‰¹æ®Šç¬¦è™Ÿæ›¿æ›
            'â€¦': '...',
            'â€”': '-',
            'â€“': '-',
            'Â©': '(c)',
            'Â®': '(r)',
            'â„¢': '(tm)',
        }
        
        replacement = replacement_map.get(char)
        if replacement:
            try:
                replacement.encode(target_encoding)
                return replacement
            except UnicodeEncodeError:
                pass
        
        return None

# å…¨åŸŸç·¨ç¢¼è½‰æ›å™¨å¯¦ä¾‹
encoding_converter = EncodingConverter()
```

---

## 3. CLI å·¥å…·è¼¸å‡ºè™•ç†ç³»çµ±

### å‘½ä»¤è¼¸å‡ºç·¨ç¢¼è™•ç†å™¨

```python
"""
CLI å·¥å…·è¼¸å‡ºç·¨ç¢¼è™•ç†å™¨
çµ±ä¸€è™•ç†å„ç¨® CLI å·¥å…·çš„ç·¨ç¢¼è¼¸å‡º
"""

import subprocess
import threading
import queue
from typing import Generator, Optional, Callable

class CommandOutputProcessor:
    """å‘½ä»¤è¼¸å‡ºç·¨ç¢¼è™•ç†å™¨"""
    
    def __init__(self):
        self.default_encoding = 'utf-8'
        self.fallback_encodings = ['utf-8', 'cp1252', 'latin1', 'ascii']
        self.tool_encoding_map = {
            # ä¸åŒå·¥å…·çš„é è¨­ç·¨ç¢¼é…ç½®
            'rg': 'utf-8',
            'ripgrep': 'utf-8', 
            'fd': 'utf-8',
            'bat': 'utf-8',
            'pandoc': 'utf-8',
            'glow': 'utf-8',
            'dust': 'utf-8',
            'glances': 'utf-8',
            # Windows å·¥å…·å¯èƒ½ä½¿ç”¨ç³»çµ±ç·¨ç¢¼
            'dir': 'cp950',
            'type': 'cp950',
            'findstr': 'cp950',
        }
    
    def execute_command_with_encoding(self,
                                    command: List[str],
                                    cwd: Optional[str] = None,
                                    timeout: Optional[int] = None,
                                    encoding: Optional[str] = None,
                                    input_data: Optional[str] = None) -> subprocess.CompletedProcess:
        """
        åŸ·è¡Œå‘½ä»¤ä¸¦è™•ç†ç·¨ç¢¼
        
        Args:
            command: å‘½ä»¤å’Œåƒæ•¸åˆ—è¡¨
            cwd: å·¥ä½œç›®éŒ„
            timeout: è¶…æ™‚æ™‚é–“
            encoding: æŒ‡å®šç·¨ç¢¼
            input_data: è¼¸å…¥æ•¸æ“š
            
        Returns:
            è™•ç†å®Œç·¨ç¢¼çš„å‘½ä»¤çµæœ
        """
        try:
            # ç¢ºå®šä½¿ç”¨çš„ç·¨ç¢¼
            if encoding is None:
                tool_name = Path(command[0]).name.lower()
                encoding = self.tool_encoding_map.get(tool_name, self.default_encoding)
            
            logger.debug(f"Executing command: {' '.join(command)} with encoding: {encoding}")
            
            # æº–å‚™è¼¸å…¥æ•¸æ“š
            input_bytes = None
            if input_data:
                input_bytes = input_data.encode(encoding)
            
            # åŸ·è¡Œå‘½ä»¤
            result = subprocess.run(
                command,
                input=input_bytes,
                capture_output=True,
                cwd=cwd,
                timeout=timeout,
                # ä¸åœ¨é€™è£¡æŒ‡å®šç·¨ç¢¼ï¼Œä½¿ç”¨å­—ç¯€æ¨¡å¼
            )
            
            # è™•ç†è¼¸å‡ºç·¨ç¢¼
            stdout_text = self._decode_output(result.stdout, encoding)
            stderr_text = self._decode_output(result.stderr, encoding)
            
            # å‰µå»ºæ–°çš„çµæœå°è±¡
            processed_result = subprocess.CompletedProcess(
                args=result.args,
                returncode=result.returncode,
                stdout=stdout_text,
                stderr=stderr_text
            )
            
            return processed_result
            
        except subprocess.TimeoutExpired as e:
            logger.error(f"Command timeout: {' '.join(command)}")
            # è™•ç†è¶…æ™‚æƒ…æ³çš„ç·¨ç¢¼
            stdout_text = self._decode_output(e.stdout, encoding) if e.stdout else ""
            stderr_text = self._decode_output(e.stderr, encoding) if e.stderr else ""
            
            raise subprocess.TimeoutExpired(
                cmd=e.cmd,
                timeout=e.timeout,
                output=stdout_text,
                stderr=stderr_text
            )
        except Exception as e:
            logger.error(f"Command execution failed: {e}")
            raise
    
    def execute_command_stream(self,
                              command: List[str],
                              cwd: Optional[str] = None,
                              encoding: Optional[str] = None,
                              line_callback: Optional[Callable[[str, str], None]] = None) -> Generator[Tuple[str, str], None, None]:
        """
        æµå¼åŸ·è¡Œå‘½ä»¤ä¸¦å³æ™‚è™•ç†ç·¨ç¢¼
        
        Args:
            command: å‘½ä»¤å’Œåƒæ•¸åˆ—è¡¨
            cwd: å·¥ä½œç›®éŒ„
            encoding: æŒ‡å®šç·¨ç¢¼
            line_callback: è¡Œå›èª¿å‡½æ•¸ (line, stream_type)
            
        Yields:
            (line, stream_type) å…¶ä¸­ stream_type ç‚º 'stdout' æˆ– 'stderr'
        """
        if encoding is None:
            tool_name = Path(command[0]).name.lower()
            encoding = self.tool_encoding_map.get(tool_name, self.default_encoding)
        
        try:
            process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                cwd=cwd,
                bufsize=1  # è¡Œç·©è¡
            )
            
            # ä½¿ç”¨ç·šç¨‹è®€å– stdout å’Œ stderr
            stdout_queue = queue.Queue()
            stderr_queue = queue.Queue()
            
            def read_stream(stream, output_queue, stream_name):
                """è®€å–æµä¸¦æ”¾å…¥ä½‡åˆ—"""
                try:
                    while True:
                        line_bytes = stream.readline()
                        if not line_bytes:
                            break
                        
                        # è§£ç¢¼è¡Œ
                        line_text = self._decode_output(line_bytes, encoding)
                        output_queue.put((line_text.rstrip('\n\r'), stream_name))
                        
                        # èª¿ç”¨å›èª¿å‡½æ•¸
                        if line_callback:
                            line_callback(line_text.rstrip('\n\r'), stream_name)
                            
                except Exception as e:
                    logger.error(f"Error reading {stream_name}: {e}")
                finally:
                    output_queue.put(None)  # çµæŸæ¨™è¨˜
            
            # å•Ÿå‹•è®€å–ç·šç¨‹
            stdout_thread = threading.Thread(
                target=read_stream, 
                args=(process.stdout, stdout_queue, 'stdout')
            )
            stderr_thread = threading.Thread(
                target=read_stream,
                args=(process.stderr, stderr_queue, 'stderr')
            )
            
            stdout_thread.start()
            stderr_thread.start()
            
            # å¾ä½‡åˆ—ä¸­è®€å–ä¸¦ç”Ÿæˆçµæœ
            active_streams = 2
            while active_streams > 0:
                # æª¢æŸ¥ stdout
                try:
                    item = stdout_queue.get_nowait()
                    if item is None:
                        active_streams -= 1
                    else:
                        yield item
                except queue.Empty:
                    pass
                
                # æª¢æŸ¥ stderr
                try:
                    item = stderr_queue.get_nowait()
                    if item is None:
                        active_streams -= 1
                    else:
                        yield item
                except queue.Empty:
                    pass
                
                # çŸ­æš«ç­‰å¾…é¿å… CPU å¯†é›†
                import time
                time.sleep(0.01)
            
            # ç­‰å¾…é€²ç¨‹å®Œæˆ
            process.wait()
            
            # ç­‰å¾…ç·šç¨‹å®Œæˆ
            stdout_thread.join()
            stderr_thread.join()
            
        except Exception as e:
            logger.error(f"Stream command execution failed: {e}")
            raise
    
    def _decode_output(self, output_bytes: bytes, preferred_encoding: str) -> str:
        """
        è§£ç¢¼è¼¸å‡ºå­—ç¯€
        
        Args:
            output_bytes: è¼¸å‡ºå­—ç¯€
            preferred_encoding: é¦–é¸ç·¨ç¢¼
            
        Returns:
            è§£ç¢¼å¾Œçš„æ–‡æœ¬
        """
        if not output_bytes:
            return ""
        
        # å˜—è©¦é¦–é¸ç·¨ç¢¼
        try:
            return output_bytes.decode(preferred_encoding)
        except UnicodeDecodeError as e:
            logger.debug(f"Failed to decode with {preferred_encoding}: {e}")
        
        # å˜—è©¦ç·¨ç¢¼æª¢æ¸¬
        try:
            detection_result = encoding_detector.detect_bytes_encoding(output_bytes)
            if detection_result.is_reliable:
                return output_bytes.decode(detection_result.encoding)
        except Exception as e:
            logger.debug(f"Encoding detection failed: {e}")
        
        # å˜—è©¦å¾Œå‚™ç·¨ç¢¼
        for encoding in self.fallback_encodings:
            if encoding == preferred_encoding:
                continue  # å·²ç¶“å˜—è©¦é
            
            try:
                return output_bytes.decode(encoding)
            except UnicodeDecodeError:
                continue
        
        # æœ€å¾Œä½¿ç”¨éŒ¯èª¤æ›¿æ›
        try:
            return output_bytes.decode(preferred_encoding, errors='replace')
        except Exception:
            return output_bytes.decode('latin1', errors='replace')
    
    def get_system_encoding(self) -> str:
        """ç²å–ç³»çµ±é è¨­ç·¨ç¢¼"""
        import locale
        import sys
        
        # å˜—è©¦å¤šç¨®æ–¹æ³•ç²å–ç³»çµ±ç·¨ç¢¼
        encodings_to_try = [
            locale.getpreferredencoding(),
            sys.stdout.encoding,
            sys.getdefaultencoding(),
            locale.getdefaultlocale()[1],
        ]
        
        for encoding in encodings_to_try:
            if encoding:
                return encoding.lower()
        
        # æ ¹æ“šå¹³å°è¿”å›é è¨­ç·¨ç¢¼
        import platform
        system = platform.system().lower()
        
        if system == 'windows':
            return 'cp950' if locale.getdefaultlocale()[0] == 'zh_TW' else 'cp1252'
        else:
            return 'utf-8'
    
    def configure_tool_encoding(self, tool_name: str, encoding: str):
        """é…ç½®ç‰¹å®šå·¥å…·çš„ç·¨ç¢¼"""
        self.tool_encoding_map[tool_name.lower()] = encoding
        logger.info(f"Configured encoding for {tool_name}: {encoding}")

# å…¨åŸŸå‘½ä»¤è¼¸å‡ºè™•ç†å™¨å¯¦ä¾‹
command_processor = CommandOutputProcessor()
```

---

## 4. æ–‡ä»¶ç³»çµ± UTF-8 è™•ç†

### å®‰å…¨æ–‡ä»¶æ“ä½œå™¨

```python
"""
UTF-8 å®‰å…¨æ–‡ä»¶æ“ä½œå™¨
ç¢ºä¿æ‰€æœ‰æ–‡ä»¶æ“ä½œéƒ½ä½¿ç”¨æ­£ç¢ºçš„ç·¨ç¢¼
"""

class UTF8FileHandler:
    """UTF-8 æ–‡ä»¶è™•ç†å™¨"""
    
    def __init__(self):
        self.default_encoding = 'utf-8'
        self.backup_enabled = True
        self.operation_history: List[Dict[str, Any]] = []
        
    def read_file_safe(self, 
                      file_path: Union[str, Path],
                      encoding: Optional[str] = None,
                      fallback_encodings: List[str] = None) -> Tuple[str, str]:
        """
        å®‰å…¨è®€å–æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘
            encoding: æŒ‡å®šç·¨ç¢¼
            fallback_encodings: å¾Œå‚™ç·¨ç¢¼åˆ—è¡¨
            
        Returns:
            (æ–‡ä»¶å…§å®¹, ä½¿ç”¨çš„ç·¨ç¢¼)
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # å¦‚æœæ²’æœ‰æŒ‡å®šç·¨ç¢¼ï¼Œå…ˆæª¢æ¸¬
        if encoding is None:
            detection_result = encoding_detector.detect_file_encoding(file_path)
            encoding = detection_result.encoding
            logger.debug(f"Detected encoding for {file_path}: {encoding}")
        
        # æº–å‚™ç·¨ç¢¼åˆ—è¡¨
        encodings_to_try = [encoding]
        if fallback_encodings:
            encodings_to_try.extend(fallback_encodings)
        else:
            encodings_to_try.extend(['utf-8', 'utf-8-sig', 'cp1252', 'latin1'])
        
        # å»é‡ä¿æŒé †åº
        seen = set()
        encodings_to_try = [x for x in encodings_to_try if not (x in seen or seen.add(x))]
        
        # å˜—è©¦è®€å–
        last_error = None
        for enc in encodings_to_try:
            try:
                with open(file_path, 'r', encoding=enc) as f:
                    content = f.read()
                
                logger.debug(f"Successfully read {file_path} with encoding {enc}")
                return content, enc
                
            except (UnicodeDecodeError, UnicodeError) as e:
                last_error = e
                logger.debug(f"Failed to read {file_path} with encoding {enc}: {e}")
                continue
            except Exception as e:
                logger.error(f"Unexpected error reading {file_path} with encoding {enc}: {e}")
                last_error = e
                continue
        
        # å¦‚æœæ‰€æœ‰ç·¨ç¢¼éƒ½å¤±æ•—ï¼Œå˜—è©¦éŒ¯èª¤æ›¿æ›
        try:
            with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                content = f.read()
            logger.warning(f"Read {file_path} with character replacement using {encoding}")
            return content, encoding
        except Exception as e:
            logger.error(f"Failed to read {file_path} even with error replacement: {e}")
            raise IOError(f"Cannot read file {file_path}: {last_error}")
    
    def write_file_safe(self,
                       file_path: Union[str, Path],
                       content: str,
                       encoding: str = 'utf-8',
                       create_backup: bool = True,
                       ensure_newline: bool = True) -> bool:
        """
        å®‰å…¨å¯«å…¥æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘
            content: æ–‡ä»¶å…§å®¹
            encoding: ç·¨ç¢¼
            create_backup: æ˜¯å¦å‰µå»ºå‚™ä»½
            ensure_newline: æ˜¯å¦ç¢ºä¿æ–‡ä»¶çµå°¾æœ‰æ›è¡Œç¬¦
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        file_path = Path(file_path)
        
        try:
            # å‰µå»ºçˆ¶ç›®éŒ„
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # å‰µå»ºå‚™ä»½
            if create_backup and file_path.exists() and self.backup_enabled:
                backup_path = self._create_backup(file_path)
                logger.debug(f"Created backup: {backup_path}")
            
            # è™•ç†å…§å®¹
            if ensure_newline and content and not content.endswith('\n'):
                content += '\n'
            
            # æª¢æŸ¥å…§å®¹æ˜¯å¦å¯ä»¥ç”¨æŒ‡å®šç·¨ç¢¼ç·¨ç¢¼
            try:
                content.encode(encoding)
            except UnicodeEncodeError as e:
                logger.warning(f"Content contains characters not encodable in {encoding}: {e}")
                # å˜—è©¦è½‰æ›
                content, success = encoding_converter.convert_text(
                    content, target_encoding=encoding, error_handling='smart_replace'
                )
                if not success:
                    logger.error(f"Failed to convert content for encoding {encoding}")
                    return False
            
            # å¯«å…¥æ–‡ä»¶
            with open(file_path, 'w', encoding=encoding, newline='\n') as f:
                f.write(content)
            
            logger.debug(f"Successfully wrote {file_path} with encoding {encoding}")
            
            # è¨˜éŒ„æ“ä½œæ­·å²
            self.operation_history.append({
                'timestamp': datetime.datetime.now().isoformat(),
                'operation': 'write',
                'file_path': str(file_path),
                'encoding': encoding,
                'success': True,
                'content_length': len(content)
            })
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to write {file_path}: {e}")
            
            # è¨˜éŒ„å¤±æ•—æ­·å²
            self.operation_history.append({
                'timestamp': datetime.datetime.now().isoformat(),
                'operation': 'write',
                'file_path': str(file_path),
                'encoding': encoding,
                'success': False,
                'error': str(e)
            })
            
            return False
    
    def copy_file_with_encoding(self,
                               source_path: Union[str, Path],
                               dest_path: Union[str, Path],
                               target_encoding: str = 'utf-8',
                               source_encoding: Optional[str] = None) -> bool:
        """
        è¤‡è£½æ–‡ä»¶ä¸¦è½‰æ›ç·¨ç¢¼
        
        Args:
            source_path: æºæ–‡ä»¶è·¯å¾‘
            dest_path: ç›®æ¨™æ–‡ä»¶è·¯å¾‘  
            target_encoding: ç›®æ¨™ç·¨ç¢¼
            source_encoding: æºç·¨ç¢¼
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # è®€å–æºæ–‡ä»¶
            content, used_encoding = self.read_file_safe(source_path, source_encoding)
            
            # å¦‚æœç·¨ç¢¼ç›¸åŒï¼Œç›´æ¥è¤‡è£½
            if used_encoding.lower() == target_encoding.lower():
                import shutil
                shutil.copy2(source_path, dest_path)
                logger.info(f"Direct copied {source_path} to {dest_path}")
                return True
            
            # å¦å‰‡è½‰æ›ç·¨ç¢¼å¾Œå¯«å…¥
            success = self.write_file_safe(dest_path, content, target_encoding)
            if success:
                logger.info(f"Copied and converted {source_path} to {dest_path} "
                          f"({used_encoding} -> {target_encoding})")
            
            return success
            
        except Exception as e:
            logger.error(f"Failed to copy file with encoding conversion: {e}")
            return False
    
    def _create_backup(self, file_path: Path) -> Path:
        """å‰µå»ºå‚™ä»½æ–‡ä»¶"""
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = file_path.with_suffix(f".{timestamp}.bak")
        
        # å¦‚æœå‚™ä»½å·²å­˜åœ¨ï¼Œæ·»åŠ åºè™Ÿ
        counter = 1
        while backup_path.exists():
            backup_path = file_path.with_suffix(f".{timestamp}_{counter}.bak")
            counter += 1
        
        import shutil
        shutil.copy2(file_path, backup_path)
        return backup_path
    
    def validate_file_encoding(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """
        é©—è­‰æ–‡ä»¶ç·¨ç¢¼
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾‘
            
        Returns:
            é©—è­‰çµæœ
        """
        file_path = Path(file_path)
        
        result = {
            'file_path': str(file_path),
            'exists': file_path.exists(),
            'is_valid_utf8': False,
            'detected_encoding': None,
            'confidence': 0.0,
            'has_bom': False,
            'line_endings': None,
            'issues': []
        }
        
        if not file_path.exists():
            result['issues'].append('File does not exist')
            return result
        
        try:
            # æª¢æ¸¬ç·¨ç¢¼
            detection_result = encoding_detector.detect_file_encoding(file_path)
            result['detected_encoding'] = detection_result.encoding
            result['confidence'] = detection_result.confidence
            result['has_bom'] = detection_result.byte_order_mark
            
            # å˜—è©¦ä»¥ UTF-8 è®€å–
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                result['is_valid_utf8'] = True
                
                # æª¢æ¸¬è¡ŒçµæŸç¬¦
                if '\r\n' in content:
                    result['line_endings'] = 'CRLF'
                elif '\n' in content:
                    result['line_endings'] = 'LF'
                elif '\r' in content:
                    result['line_endings'] = 'CR'
                
            except UnicodeDecodeError:
                result['is_valid_utf8'] = False
                result['issues'].append('File is not valid UTF-8')
            
            # å¦‚æœæª¢æ¸¬çµæœä¸å¯é ï¼Œæ·»åŠ è­¦å‘Š
            if not detection_result.is_reliable:
                result['issues'].append(f'Encoding detection not reliable (confidence: {detection_result.confidence:.2f})')
            
        except Exception as e:
            result['issues'].append(f'Validation error: {str(e)}')
        
        return result

# å…¨åŸŸæ–‡ä»¶è™•ç†å™¨å¯¦ä¾‹
utf8_file_handler = UTF8FileHandler()
```

---

## 5. å°ˆæ¡ˆæ•´åˆå’Œé…ç½®

### åœ¨ç¾æœ‰å°ˆæ¡ˆä¸­æ•´åˆç·¨ç¢¼è™•ç†

```python
# åœ¨ main_app.py ä¸­æ•´åˆç·¨ç¢¼è™•ç†
import sys
import os
import locale

def setup_encoding_environment():
    """è¨­ç½®ç·¨ç¢¼ç’°å¢ƒ"""
    try:
        # è¨­ç½® Python é è¨­ç·¨ç¢¼
        if hasattr(sys, 'setdefaultencoding'):
            sys.setdefaultencoding('utf-8')
        
        # è¨­ç½®ç’°å¢ƒè®Šæ•¸
        os.environ['PYTHONIOENCODING'] = 'utf-8'
        
        # Windows ç‰¹æ®Šè™•ç†
        if sys.platform == 'win32':
            try:
                # å˜—è©¦è¨­ç½®æ§åˆ¶å°ç·¨ç¢¼ç‚º UTF-8
                import subprocess
                subprocess.run(['chcp', '65001'], shell=True, check=False)
            except:
                pass
        
        logger.info(f"Encoding environment setup complete. System encoding: {locale.getpreferredencoding()}")
        
    except Exception as e:
        logger.warning(f"Failed to setup encoding environment: {e}")

class EncodingAwareApplication(QApplication):
    """ç·¨ç¢¼æ„ŸçŸ¥çš„æ‡‰ç”¨ç¨‹å¼é¡"""
    
    def __init__(self, sys_argv):
        # åœ¨ QApplication åˆå§‹åŒ–å‰è¨­ç½®ç·¨ç¢¼
        setup_encoding_environment()
        super().__init__(sys_argv)
        
        self.encoding_system = UTF8EncodingSystem()
        self.setup_encoding_handling()
    
    def setup_encoding_handling(self):
        """è¨­ç½®ç·¨ç¢¼è™•ç†"""
        # è¨­ç½®å…¨åŸŸç•°å¸¸è™•ç†
        sys.excepthook = self.handle_encoding_exception
        
        # é…ç½®æ—¥èªŒç·¨ç¢¼
        self.setup_logging_encoding()
    
    def handle_encoding_exception(self, exc_type, exc_value, exc_traceback):
        """è™•ç†ç·¨ç¢¼ç›¸é—œç•°å¸¸"""
        if isinstance(exc_value, UnicodeEncodeError):
            logger.error(f"Unicode encode error: {exc_value}")
            # å˜—è©¦æ¢å¾©
            self.recover_from_encoding_error(exc_value)
        elif isinstance(exc_value, UnicodeDecodeError):
            logger.error(f"Unicode decode error: {exc_value}")
            # å˜—è©¦æ¢å¾©
            self.recover_from_encoding_error(exc_value)
        else:
            # èª¿ç”¨ç³»çµ±é è¨­ç•°å¸¸è™•ç†
            sys.__excepthook__(exc_type, exc_value, exc_traceback)
    
    def recover_from_encoding_error(self, error):
        """å¾ç·¨ç¢¼éŒ¯èª¤ä¸­æ¢å¾©"""
        logger.info("Attempting to recover from encoding error...")
        # é€™è£¡å¯ä»¥å¯¦ç¾å…·é«”çš„æ¢å¾©é‚è¼¯
        # ä¾‹å¦‚ï¼šé‡æ–°æª¢æ¸¬ç·¨ç¢¼ã€ä½¿ç”¨å¾Œå‚™ç·¨ç¢¼ç­‰
        pass
    
    def setup_logging_encoding(self):
        """è¨­ç½®æ—¥èªŒç·¨ç¢¼"""
        import logging
        
        # ç¢ºä¿æ—¥èªŒè™•ç†å™¨ä½¿ç”¨ UTF-8
        for handler in logging.getLogger().handlers:
            if hasattr(handler, 'stream') and hasattr(handler.stream, 'reconfigure'):
                try:
                    handler.stream.reconfigure(encoding='utf-8')
                except:
                    pass

# ä¿®æ”¹ä¸»ç¨‹åºå…¥å£
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # å‰µå»ºç·¨ç¢¼æ„ŸçŸ¥çš„æ‡‰ç”¨ç¨‹å¼
    app = EncodingAwareApplication(sys.argv)
    
    # ... å…¶é¤˜æ‡‰ç”¨ç¨‹å¼åˆå§‹åŒ–ä»£ç¢¼
    
    return app.exec_()
```

### CLI å·¥å…·æ¨¡å‹æ›´æ–°

```python
# æ›´æ–° ripgrep_model.py ç­‰ CLI å·¥å…·æ¨¡å‹
class RipgrepModelUTF8(RipgrepModel):
    """å¢å¼·çš„ Ripgrep æ¨¡å‹ï¼Œæ”¯æ´ UTF-8 è™•ç†"""
    
    def __init__(self):
        super().__init__()
        self.command_processor = CommandOutputProcessor()
        
    def execute_search_command(self, search_params):
        """åŸ·è¡Œæœç´¢å‘½ä»¤ä¸¦è™•ç†ç·¨ç¢¼"""
        try:
            command = self._build_command(search_params)
            
            # ä½¿ç”¨ç·¨ç¢¼æ„ŸçŸ¥çš„å‘½ä»¤åŸ·è¡Œå™¨
            result = self.command_processor.execute_command_with_encoding(
                command=command,
                cwd=search_params.search_path,
                encoding='utf-8',
                timeout=search_params.timeout
            )
            
            if result.returncode == 0:
                return self._parse_search_results(result.stdout)
            else:
                logger.error(f"Search command failed: {result.stderr}")
                return []
                
        except Exception as e:
            logger.error(f"Search execution error: {e}")
            return []
    
    def execute_search_stream(self, search_params, callback):
        """æµå¼åŸ·è¡Œæœç´¢ä¸¦è™•ç†ç·¨ç¢¼"""
        try:
            command = self._build_command(search_params)
            
            # ä½¿ç”¨æµå¼ç·¨ç¢¼è™•ç†
            for line, stream_type in self.command_processor.execute_command_stream(
                command=command,
                cwd=search_params.search_path,
                encoding='utf-8',
                line_callback=callback
            ):
                if stream_type == 'stdout' and line.strip():
                    result = self._parse_single_result_line(line)
                    if result:
                        callback(result, 'result')
                elif stream_type == 'stderr' and line.strip():
                    callback(line, 'error')
                    
        except Exception as e:
            logger.error(f"Stream search error: {e}")
            callback(str(e), 'error')

# é¡ä¼¼åœ°æ›´æ–°å…¶ä»– CLI å·¥å…·æ¨¡å‹
```

### é…ç½®æ–‡ä»¶æ›´æ–°

```yaml
# config/encoding_settings.yaml
encoding_system:
  # å…¨åŸŸç·¨ç¢¼è¨­å®š
  default_encoding: "utf-8"
  console_encoding: "auto"  # auto, utf-8, cp950, etc.
  file_encoding: "utf-8"
  
  # ç·¨ç¢¼æª¢æ¸¬è¨­å®š
  detection:
    enabled: true
    confidence_threshold: 0.8
    cache_results: true
    max_detection_size: 10240  # 10KB
  
  # ç·¨ç¢¼è½‰æ›è¨­å®š
  conversion:
    create_backups: true
    error_handling: "smart_replace"  # strict, ignore, replace, smart_replace
    batch_processing: true
  
  # CLI å·¥å…·ç·¨ç¢¼æ˜ å°„
  cli_tools:
    ripgrep: "utf-8"
    fd: "utf-8" 
    bat: "utf-8"
    pandoc: "utf-8"
    glow: "utf-8"
    dust: "utf-8"
    glances: "utf-8"
  
  # å¹³å°ç‰¹å®šè¨­å®š
  platform_specific:
    windows:
      console_codepage: 65001  # UTF-8
      fallback_encoding: "cp950"
    linux:
      locale_encoding: "utf-8"
    darwin:
      locale_encoding: "utf-8"
  
  # éŒ¯èª¤è™•ç†è¨­å®š
  error_handling:
    log_encoding_errors: true
    auto_recovery: true
    fallback_encodings: ["utf-8", "cp1252", "latin1", "ascii"]
  
  # æª”æ¡ˆè™•ç†è¨­å®š
  file_operations:
    default_line_ending: "auto"  # auto, lf, crlf, cr
    preserve_bom: false
    normalize_encoding: true
```

---

## 6. æ¸¬è©¦å’Œé©—è­‰

### ç·¨ç¢¼è™•ç†æ¸¬è©¦å¥—ä»¶

```python
"""
ç·¨ç¢¼è™•ç†ç³»çµ±æ¸¬è©¦å¥—ä»¶
"""

import pytest
import tempfile
from pathlib import Path

class TestUTF8EncodingSystem:
    """UTF-8 ç·¨ç¢¼ç³»çµ±æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.test_encodings = ['utf-8', 'utf-8-sig', 'cp950', 'gbk', 'big5', 'latin1']
        
    def teardown_method(self):
        """æ¸…ç†æ¸¬è©¦"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_encoding_detection(self):
        """æ¸¬è©¦ç·¨ç¢¼æª¢æ¸¬"""
        test_content = "Hello ä¸–ç•Œ ğŸŒ"
        
        for encoding in self.test_encodings:
            try:
                # å‰µå»ºæ¸¬è©¦æª”æ¡ˆ
                test_file = self.temp_dir / f"test_{encoding}.txt"
                with open(test_file, 'w', encoding=encoding) as f:
                    f.write(test_content)
                
                # æª¢æ¸¬ç·¨ç¢¼
                result = encoding_detector.detect_file_encoding(test_file)
                
                # é©—è­‰çµæœ
                assert result.encoding is not None
                assert result.confidence > 0
                
                if encoding in ['utf-8', 'ascii']:
                    assert result.is_utf8_compatible
                    
            except UnicodeEncodeError:
                # æŸäº›ç·¨ç¢¼å¯èƒ½ç„¡æ³•ç·¨ç¢¼æ¸¬è©¦å…§å®¹ï¼Œè·³é
                continue
    
    def test_encoding_conversion(self):
        """æ¸¬è©¦ç·¨ç¢¼è½‰æ›"""
        test_content = "æ¸¬è©¦æ–‡æœ¬ Test Content ğŸ¯"
        
        # æ¸¬è©¦æ–‡æœ¬è½‰æ›
        converted_text, success = encoding_converter.convert_text(
            test_content, 
            target_encoding='utf-8'
        )
        
        assert success
        assert converted_text == test_content
    
    def test_file_operations(self):
        """æ¸¬è©¦æª”æ¡ˆæ“ä½œ"""
        test_content = "UTF-8 æ¸¬è©¦å…§å®¹\nåŒ…å«ä¸­æ–‡å’Œç‰¹æ®Šå­—ç¬¦ Â©Â®â„¢"
        test_file = self.temp_dir / "test_utf8.txt"
        
        # å¯«å…¥æª”æ¡ˆ
        success = utf8_file_handler.write_file_safe(
            test_file, 
            test_content,
            encoding='utf-8'
        )
        assert success
        
        # è®€å–æª”æ¡ˆ
        content, encoding = utf8_file_handler.read_file_safe(test_file)
        assert content == test_content
        assert encoding == 'utf-8'
    
    def test_cli_command_processing(self):
        """æ¸¬è©¦ CLI å‘½ä»¤è™•ç†"""
        # æ¸¬è©¦ç°¡å–®å‘½ä»¤
        result = command_processor.execute_command_with_encoding(
            ['echo', 'æ¸¬è©¦è¼¸å‡º'],
            encoding='utf-8'
        )
        
        assert result.returncode == 0
        assert 'æ¸¬è©¦è¼¸å‡º' in result.stdout
    
    def test_error_handling(self):
        """æ¸¬è©¦éŒ¯èª¤è™•ç†"""
        # æ¸¬è©¦ç„¡æ•ˆæª”æ¡ˆ
        with pytest.raises(FileNotFoundError):
            utf8_file_handler.read_file_safe('/nonexistent/file.txt')
        
        # æ¸¬è©¦ç·¨ç¢¼éŒ¯èª¤æ¢å¾©
        problematic_content = "Content with problematic chars: \udcff"
        converted, success = encoding_converter.convert_text(
            problematic_content,
            target_encoding='utf-8',
            error_handling='smart_replace'
        )
        # æ‡‰è©²æˆåŠŸä½†å¯èƒ½æœ‰å­—ç¬¦æ›¿æ›
        assert isinstance(converted, str)
    
    def test_batch_conversion(self):
        """æ¸¬è©¦æ‰¹é‡è½‰æ›"""
        # å‰µå»ºå¤šå€‹æ¸¬è©¦æª”æ¡ˆ
        test_files = []
        for i, encoding in enumerate(['utf-8', 'latin1']):
            try:
                test_file = self.temp_dir / f"batch_test_{i}.txt"
                with open(test_file, 'w', encoding=encoding) as f:
                    f.write(f"Test content {i}")
                test_files.append(test_file)
            except UnicodeEncodeError:
                continue
        
        # åŸ·è¡Œæ‰¹é‡è½‰æ›
        results = encoding_converter.batch_convert_directory(
            self.temp_dir,
            target_encoding='utf-8',
            file_patterns=['*.txt']
        )
        
        assert results['total_files'] > 0
        assert results['success_count'] >= 0

if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

---

## ç¸½çµ

é€™ä»½ UTF-8 ç·¨ç¢¼æ¨™æº–åŒ–è™•ç†æŒ‡å—æä¾›äº†å®Œæ•´çš„ç·¨ç¢¼è™•ç†è§£æ±ºæ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

### âœ¨ æ ¸å¿ƒç‰¹è‰²
- **å…¨é¢ç·¨ç¢¼æª¢æ¸¬** - æ”¯æ´å¤šç¨®ç·¨ç¢¼æ ¼å¼çš„æ™ºèƒ½æª¢æ¸¬
- **å®‰å…¨ç·¨ç¢¼è½‰æ›** - æä¾›å¤šç¨®éŒ¯èª¤è™•ç†ç­–ç•¥çš„è½‰æ›åŠŸèƒ½
- **CLI å·¥å…·æ•´åˆ** - çµ±ä¸€è™•ç†å„ç¨®å‘½ä»¤åˆ—å·¥å…·çš„ç·¨ç¢¼è¼¸å‡º
- **ä¸­æ–‡å’Œ CJK æ”¯æ´** - ç‰¹åˆ¥é‡å°ä¸­æ–‡ç’°å¢ƒå„ªåŒ–çš„ç·¨ç¢¼è™•ç†
- **æª”æ¡ˆç³»çµ±æ•´åˆ** - ç¢ºä¿æ‰€æœ‰æª”æ¡ˆæ“ä½œä½¿ç”¨æ­£ç¢ºç·¨ç¢¼

### ğŸ”§ æŠ€è¡“äº®é»
- **æ™ºèƒ½ç·¨ç¢¼æª¢æ¸¬** - çµåˆå¤šç¨®æª¢æ¸¬æ–¹æ³•æé«˜æº–ç¢ºæ€§
- **è·¨å¹³å°å…¼å®¹** - è™•ç† Windowsã€Linuxã€macOS çš„ç·¨ç¢¼å·®ç•°
- **éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶** - å®Œå–„çš„éŒ¯èª¤è™•ç†å’Œæ•¸æ“šæ¢å¾©åŠŸèƒ½
- **æ€§èƒ½å„ªåŒ–** - å¿«å–æ©Ÿåˆ¶å’Œæ‰¹é‡è™•ç†æå‡æ•ˆç‡
- **å…¨é¢æ¸¬è©¦è¦†è“‹** - å®Œæ•´çš„æ¸¬è©¦å¥—ä»¶ç¢ºä¿å¯é æ€§

### ğŸŒŸ å¯¦éš›æ‡‰ç”¨æ•ˆæœ
- âœ… **è§£æ±º Windows cp950 å•é¡Œ** - å¾¹åº•ä¿®å¾©æ§åˆ¶å°ç·¨ç¢¼è¡çª
- âœ… **çµ±ä¸€ CLI å·¥å…·è¼¸å‡º** - ç¢ºä¿æ‰€æœ‰å·¥å…·è¼¸å‡ºä½¿ç”¨ UTF-8
- âœ… **ä¸­æ–‡æ”¯æ´å¢å¼·** - å®Œç¾æ”¯æ´ç¹é«”å’Œç°¡é«”ä¸­æ–‡
- âœ… **æª”æ¡ˆæ“ä½œå®‰å…¨** - é¿å…ç·¨ç¢¼éŒ¯èª¤å°è‡´çš„æ•¸æ“šæå¤±
- âœ… **é–‹ç™¼é«”é©—æå‡** - é–‹ç™¼è€…ç„¡éœ€é—œå¿ƒç·¨ç¢¼ç´°ç¯€

é€™å€‹ç·¨ç¢¼è™•ç†ç³»çµ±å°‡å®Œå…¨è§£æ±º CLI Tool å°ˆæ¡ˆä¸­çš„ç·¨ç¢¼å•é¡Œï¼Œè®“æ‡‰ç”¨ç¨‹å¼åœ¨å„ç¨®èªè¨€ç’°å¢ƒä¸‹éƒ½èƒ½ç©©å®šé‹è¡Œï¼ğŸŒ