#!/usr/bin/env python3
"""
Ripgrep æ’ä»¶æ€§èƒ½åŸºæº–æ¸¬è©¦
æ¸¬é‡é—œéµæ“ä½œçš„æ€§èƒ½æŒ‡æ¨™
"""
import sys
import os
import time
import tempfile
import shutil
import threading
from pathlib import Path
from typing import Dict, List

# è¨­å®šè·¯å¾‘
sys.path.append(os.path.dirname(__file__))

# å°å…¥æ¸¬è©¦ç›®æ¨™
from core.plugin_manager import plugin_manager

class PerformanceBenchmark:
    """æ€§èƒ½åŸºæº–æ¸¬è©¦é¡"""
    
    def __init__(self):
        self.results = {}
        self.test_data_dir = None
        self.plugin = None
    
    def setup_large_test_dataset(self, num_files: int = 100, lines_per_file: int = 1000):
        """å‰µå»ºå¤§å‹æ¸¬è©¦è³‡æ–™é›†"""
        print(f"å‰µå»ºæ¸¬è©¦è³‡æ–™é›†: {num_files} å€‹æª”æ¡ˆï¼Œæ¯å€‹ {lines_per_file} è¡Œ...")
        
        self.test_data_dir = Path(tempfile.mkdtemp(prefix="ripgrep_perf_"))
        
        # å‰µå»ºå„ç¨®é¡å‹çš„æª”æ¡ˆ
        file_templates = {
            'python': '''#!/usr/bin/env python3
"""Generated Python file for performance testing"""
import os
import sys
from typing import List, Dict, Any

class TestClass_{file_idx}:
    def __init__(self):
        self.data = []
        self.search_pattern = "performance_test_{line_idx}"
    
    def process_data(self):
        """Process data method {line_idx}"""
        for item in self.data:
            if "search_term" in str(item):
                yield item
    
    def search_function_{line_idx}(self, pattern: str) -> List[str]:
        """Search function for line {line_idx}"""
        results = []
        # This is line {line_idx} with search content
        if pattern in "test_data_line_{line_idx}":
            results.append(f"match_found_at_line_{line_idx}")
        return results

def main_function_{line_idx}():
    """Main function for line {line_idx}"""
    test_obj = TestClass_{file_idx}()
    return test_obj.search_function_{line_idx}("search_term")

# Global variable for line {line_idx}
GLOBAL_SEARCH_DATA_{line_idx} = "test_content_{line_idx}_with_patterns"
''',
            
            'javascript': '''// JavaScript file {file_idx} for performance testing
const fs = require('fs');
const path = require('path');

/**
 * Search function for line {line_idx}
 * @param {{string}} searchTerm - Search term
 * @returns {{Array}} Results
 */
function searchFunction_{line_idx}(searchTerm) {{
    const data_{line_idx} = "test_data_line_{line_idx}_with_search_pattern";
    const results = [];
    
    // Line {line_idx} processing
    if (data_{line_idx}.includes(searchTerm)) {{
        results.push({{
            lineNumber: {line_idx},
            content: data_{line_idx},
            match: true,
            performance_marker: "line_{line_idx}"
        }});
    }}
    
    return results;
}}

// Export for line {line_idx}
module.exports = {{
    searchFunction_{line_idx},
    testData_{line_idx}: "search_content_line_{line_idx}"
}};

// Performance test data for line {line_idx}
const PERF_DATA_{line_idx} = {{
    timestamp: new Date().toISOString(),
    line: {line_idx},
    searchable: "performance_test_content_{line_idx}"
}};
''',
            
            'text': '''Line {line_idx}: This is performance test content for searching
Search pattern {line_idx}: performance_test_marker_{line_idx}
Content line {line_idx}: Various text content for testing search functionality
Data line {line_idx}: test_data_{line_idx}_searchable_content_{line_idx}
Pattern line {line_idx}: regex_pattern_\\d+_line_{line_idx}
Unicode line {line_idx}: æ¸¬è©¦å…§å®¹_{line_idx} ğŸ” search_emoji_{line_idx}
Log line {line_idx}: 2024-01-01 10:00:{line_idx:02d} INFO Processing request {line_idx}
Error line {line_idx}: 2024-01-01 10:00:{line_idx:02d} ERROR Connection failed at line {line_idx}
Debug line {line_idx}: 2024-01-01 10:00:{line_idx:02d} DEBUG Search completed for line {line_idx}
End line {line_idx}: Final content for performance testing line {line_idx}
'''
        }
        
        # å‰µå»ºæª”æ¡ˆ
        for file_idx in range(num_files):
            for ext, template in file_templates.items():
                file_path = self.test_data_dir / f"test_file_{file_idx:03d}.{ext}"
                
                content_lines = []
                for line_idx in range(lines_per_file):
                    line_content = template.format(file_idx=file_idx, line_idx=line_idx)
                    content_lines.append(line_content)
                
                file_path.write_text('\n'.join(content_lines), encoding='utf-8')
        
        total_files = len(list(self.test_data_dir.glob("*")))
        total_lines = total_files * lines_per_file
        print(f"æ¸¬è©¦è³‡æ–™é›†å‰µå»ºå®Œæˆ: {total_files} å€‹æª”æ¡ˆï¼Œç´„ {total_lines:,} è¡Œ")
        
        return total_files, total_lines
    
    def measure_execution_time(self, func, *args, **kwargs):
        """æ¸¬é‡å‡½æ•¸åŸ·è¡Œæ™‚é–“"""
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            success = True
        except Exception as e:
            result = str(e)
            success = False
        
        end_time = time.time()
        
        return {
            'result': result,
            'success': success,
            'execution_time': end_time - start_time
        }
    
    def benchmark_plugin_loading(self):
        """åŸºæº–æ¸¬è©¦: æ’ä»¶è¼‰å…¥æ€§èƒ½"""
        print("\næ¸¬è©¦æ’ä»¶è¼‰å…¥æ€§èƒ½...")
        
        def load_plugins():
            plugin_manager.discover_plugins()
            return plugin_manager.get_all_plugins()
        
        # åŸ·è¡Œå¤šæ¬¡æ¸¬é‡
        times = []
        for i in range(5):
            result = self.measure_execution_time(load_plugins)
            times.append(result['execution_time'])
            if i == 0:  # è¨˜éŒ„ç¬¬ä¸€æ¬¡çš„è©³ç´°è³‡è¨Š
                self.results['plugin_loading'] = result
        
        avg_time = sum(times) / len(times)
        self.results['plugin_loading']['average_time'] = avg_time
        
        print(f"  å¹³å‡è¼‰å…¥æ™‚é–“: {avg_time:.3f}s")
        
        # ç²å–æ’ä»¶å¯¦ä¾‹
        plugins = self.results['plugin_loading']['result']
        self.plugin = plugins.get('ripgrep') if plugins else None
    
    def benchmark_mvc_creation(self):
        """åŸºæº–æ¸¬è©¦: MVC çµ„ä»¶å‰µå»ºæ€§èƒ½"""
        print("\næ¸¬è©¦ MVC çµ„ä»¶å‰µå»ºæ€§èƒ½...")
        
        if not self.plugin:
            print("  è·³é: æ’ä»¶ä¸å¯ç”¨")
            return
        
        def create_mvc_components():
            try:
                from PyQt5.QtWidgets import QApplication
                if not QApplication.instance():
                    app = QApplication(sys.argv)
                
                model = self.plugin.create_model()
                view = self.plugin.create_view()
                
                if model and view:
                    controller = self.plugin.create_controller(model, view)
                    
                    # æ¸…ç†
                    if hasattr(controller, 'cleanup'):
                        controller.cleanup()
                    if hasattr(view, 'deleteLater'):
                        view.deleteLater()
                    if hasattr(model, 'cleanup'):
                        model.cleanup()
                    
                    return True
                return False
                
            except ImportError:
                return "PyQt5 not available"
        
        result = self.measure_memory_usage(create_mvc_components)
        self.results['mvc_creation'] = result
        
        print(f"  MVC å‰µå»ºæ™‚é–“: {result['execution_time']:.3f}s")
        print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {result['memory_delta_mb']:.1f}MB")
        print(f"  å‰µå»ºæˆåŠŸ: {result['success']}")
    
    def benchmark_search_parameters(self):
        """åŸºæº–æ¸¬è©¦: æœå°‹åƒæ•¸å‰µå»ºå’Œé©—è­‰æ€§èƒ½"""
        print("\næ¸¬è©¦æœå°‹åƒæ•¸æ€§èƒ½...")
        
        def create_search_params():
            try:
                from tools.ripgrep.core.data_models import SearchParameters
                
                # å‰µå»ºå„ç¨®è¤‡é›œåº¦çš„æœå°‹åƒæ•¸
                params_list = []
                
                # ç°¡å–®åƒæ•¸
                params_list.append(SearchParameters(
                    pattern="simple_search",
                    search_path=str(self.test_data_dir)
                ))
                
                # è¤‡é›œåƒæ•¸
                params_list.append(SearchParameters(
                    pattern=r"\w+@\w+\.\w+",  # æ­£å‰‡è¡¨é”å¼
                    search_path=str(self.test_data_dir),
                    case_sensitive=True,
                    whole_words=True,
                    regex_mode=True,
                    context_lines=5,
                    file_types=['*.py', '*.js', '*.txt']
                ))
                
                return len(params_list)
                
            except Exception as e:
                return str(e)
        
        result = self.measure_memory_usage(create_search_params)
        self.results['search_parameters'] = result
        
        print(f"  åƒæ•¸å‰µå»ºæ™‚é–“: {result['execution_time']:.3f}s")
        print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {result['memory_delta_mb']:.1f}MB")
    
    def benchmark_export_performance(self):
        """åŸºæº–æ¸¬è©¦: åŒ¯å‡ºåŠŸèƒ½æ€§èƒ½"""
        print("\næ¸¬è©¦åŒ¯å‡ºæ€§èƒ½...")
        
        if not self.plugin:
            print("  è·³é: æ’ä»¶ä¸å¯ç”¨")
            return
        
        def test_export():
            try:
                from tools.ripgrep.core.data_models import FileResult, SearchMatch
                
                model = self.plugin.create_model()
                if not model:
                    return False
                
                # å‰µå»ºå¤§é‡æ¸¬è©¦è³‡æ–™
                for i in range(100):  # 100 å€‹æª”æ¡ˆçµæœ
                    file_result = FileResult(file_path=f"test_{i}.py")
                    
                    for j in range(10):  # æ¯å€‹æª”æ¡ˆ 10 å€‹åŒ¹é…
                        match = SearchMatch(
                            line_number=j+1,
                            column=0,
                            content=f"test content line {j} in file {i}"
                        )
                        file_result.add_match(match)
                    
                    model.search_results.append(file_result)
                
                # æ¸¬è©¦å„ç¨®æ ¼å¼åŒ¯å‡º
                formats = ['json', 'csv', 'txt']
                export_times = {}
                
                for fmt in formats:
                    with tempfile.NamedTemporaryFile(suffix=f'.{fmt}', delete=False) as tmp:
                        start = time.time()
                        success = model.export_results(tmp.name, fmt)
                        export_times[fmt] = time.time() - start
                        
                        if success:
                            file_size = os.path.getsize(tmp.name)
                            export_times[f'{fmt}_size'] = file_size
                        
                        try:
                            os.unlink(tmp.name)
                        except:
                            pass
                
                # æ¸…ç†
                if hasattr(model, 'cleanup'):
                    model.cleanup()
                
                return export_times
                
            except Exception as e:
                return str(e)
        
        result = self.measure_memory_usage(test_export)
        self.results['export_performance'] = result
        
        if result['success'] and isinstance(result['result'], dict):
            print(f"  åŒ¯å‡ºæ¸¬è©¦æ™‚é–“: {result['execution_time']:.3f}s")
            print(f"  è¨˜æ†¶é«”ä½¿ç”¨: {result['memory_delta_mb']:.1f}MB")
            
            export_times = result['result']
            for fmt in ['json', 'csv', 'txt']:
                if fmt in export_times:
                    size_key = f'{fmt}_size'
                    size_info = f" ({export_times[size_key]} bytes)" if size_key in export_times else ""
                    print(f"    {fmt.upper()}: {export_times[fmt]:.3f}s{size_info}")
        else:
            print(f"  åŒ¯å‡ºæ¸¬è©¦å¤±æ•—: {result['result']}")
    
    def run_all_benchmarks(self):
        """åŸ·è¡Œæ‰€æœ‰åŸºæº–æ¸¬è©¦"""
        print("=" * 60)
        print("Ripgrep æ’ä»¶æ€§èƒ½åŸºæº–æ¸¬è©¦")
        print("=" * 60)
        
        start_time = time.time()
        
        # å‰µå»ºæ¸¬è©¦è³‡æ–™é›†
        total_files, total_lines = self.setup_large_test_dataset(50, 500)  # è¼ƒå°çš„è³‡æ–™é›†ä»¥é¿å…è¶…æ™‚
        
        # åŸ·è¡Œå„é …åŸºæº–æ¸¬è©¦
        self.benchmark_plugin_loading()
        self.benchmark_mvc_creation()
        self.benchmark_search_parameters()
        self.benchmark_export_performance()
        
        total_time = time.time() - start_time
        
        # ç”Ÿæˆæ€§èƒ½å ±å‘Š
        self.generate_performance_report(total_time, total_files, total_lines)
        
        return self.analyze_performance_results()
    
    def generate_performance_report(self, total_time: float, total_files: int, total_lines: int):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        print("\n" + "=" * 60)
        print("æ€§èƒ½åŸºæº–æ¸¬è©¦å ±å‘Š")
        print("=" * 60)
        
        print(f"æ¸¬è©¦è³‡æ–™è¦æ¨¡: {total_files} æª”æ¡ˆï¼Œ{total_lines:,} è¡Œ")
        print(f"ç¸½æ¸¬è©¦æ™‚é–“: {total_time:.2f}s")
        
        print("\næ€§èƒ½æŒ‡æ¨™æ‘˜è¦:")
        
        for test_name, result in self.results.items():
            if isinstance(result, dict) and 'execution_time' in result:
                time_str = f"{result['execution_time']:.3f}s"
                memory_str = f"{result.get('memory_delta_mb', 0):.1f}MB"
                success_str = "âœ“" if result.get('success', False) else "âœ—"
                
                print(f"  {test_name:20s}: {time_str:>8s} | {memory_str:>8s} | {success_str}")
        
        # æ€§èƒ½è©•ä¼°
        print("\næ€§èƒ½è©•ä¼°:")
        
        # è¼‰å…¥æ™‚é–“è©•ä¼°
        if 'plugin_loading' in self.results:
            load_time = self.results['plugin_loading'].get('average_time', 0)
            if load_time < 1.0:
                print("  âœ“ æ’ä»¶è¼‰å…¥é€Ÿåº¦: å„ªç§€ (<1s)")
            elif load_time < 3.0:
                print("  â—‹ æ’ä»¶è¼‰å…¥é€Ÿåº¦: è‰¯å¥½ (<3s)")
            else:
                print("  âœ— æ’ä»¶è¼‰å…¥é€Ÿåº¦: éœ€è¦å„ªåŒ– (>3s)")
        
        # MVC å‰µå»ºè©•ä¼°
        if 'mvc_creation' in self.results:
            mvc_time = self.results['mvc_creation'].get('execution_time', 0)
            if mvc_time < 2.0:
                print("  âœ“ MVC å‰µå»ºé€Ÿåº¦: å„ªç§€ (<2s)")
            elif mvc_time < 5.0:
                print("  â—‹ MVC å‰µå»ºé€Ÿåº¦: è‰¯å¥½ (<5s)")
            else:
                print("  âœ— MVC å‰µå»ºé€Ÿåº¦: éœ€è¦å„ªåŒ– (>5s)")
        
        # è¨˜æ†¶é«”ä½¿ç”¨è©•ä¼°
        total_memory = sum(r.get('memory_delta_mb', 0) for r in self.results.values() if isinstance(r, dict))
        if total_memory < 50:
            print(f"  âœ“ è¨˜æ†¶é«”ä½¿ç”¨: å„ªç§€ ({total_memory:.1f}MB)")
        elif total_memory < 100:
            print(f"  â—‹ è¨˜æ†¶é«”ä½¿ç”¨: è‰¯å¥½ ({total_memory:.1f}MB)")
        else:
            print(f"  âœ— è¨˜æ†¶é«”ä½¿ç”¨: éœ€è¦å„ªåŒ– ({total_memory:.1f}MB)")
    
    def analyze_performance_results(self) -> bool:
        """åˆ†ææ€§èƒ½çµæœ"""
        # æª¢æŸ¥é—œéµæ€§èƒ½æŒ‡æ¨™
        issues = []
        
        if 'plugin_loading' in self.results:
            load_time = self.results['plugin_loading'].get('average_time', 0)
            if load_time > 5.0:
                issues.append(f"æ’ä»¶è¼‰å…¥æ™‚é–“éé•·: {load_time:.2f}s")
        
        if 'mvc_creation' in self.results:
            mvc_time = self.results['mvc_creation'].get('execution_time', 0)
            if mvc_time > 10.0:
                issues.append(f"MVC å‰µå»ºæ™‚é–“éé•·: {mvc_time:.2f}s")
        
        # æª¢æŸ¥è¨˜æ†¶é«”æ´©æ¼
        total_memory = sum(r.get('memory_delta_mb', 0) for r in self.results.values() if isinstance(r, dict))
        if total_memory > 200:
            issues.append(f"è¨˜æ†¶é«”ä½¿ç”¨éå¤š: {total_memory:.1f}MB")
        
        if issues:
            print(f"\næ€§èƒ½å•é¡Œ:")
            for issue in issues:
                print(f"  - {issue}")
            return False
        
        return True
    
    def cleanup(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        if self.test_data_dir and self.test_data_dir.exists():
            shutil.rmtree(self.test_data_dir)
            print("\næ¸¬è©¦è³‡æ–™æ¸…ç†å®Œæˆ")

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    benchmark = PerformanceBenchmark()
    
    try:
        success = benchmark.run_all_benchmarks()
        
        print("\n" + "=" * 60)
        if success:
            print("æ€§èƒ½åŸºæº–æ¸¬è©¦é€šéï¼Ripgrep æ’ä»¶æ€§èƒ½ç¬¦åˆæ¨™æº–ã€‚")
        else:
            print("æ€§èƒ½åŸºæº–æ¸¬è©¦ç™¼ç¾å•é¡Œï¼Œå»ºè­°é€²è¡Œå„ªåŒ–ã€‚")
        print("=" * 60)
        
        return 0 if success else 1
        
    except Exception as e:
        print(f"\næ€§èƒ½æ¸¬è©¦åŸ·è¡Œç•°å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1
        
    finally:
        benchmark.cleanup()

if __name__ == "__main__":
    sys.exit(main())